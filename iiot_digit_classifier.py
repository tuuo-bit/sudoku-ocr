# -*- coding: utf-8 -*-
"""iiot_Digit_Classifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gNiIWDxvHPMaSSWoqlaY94gSeZz62AFW
"""

from tensorflow.keras.layers import Input,Dense,Conv2D,MaxPooling2D,Flatten,Dropout
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.datasets import mnist
from sklearn.preprocessing import LabelBinarizer
from sklearn.metrics import classification_report

model = Sequential([
    Conv2D( 32, (5,5), padding = "same", input_shape = (28,28,1), activation = "relu"),
    MaxPooling2D( pool_size = (2,2)),
    Conv2D( 32, (3,3), padding = "same", activation = "relu"),
    MaxPooling2D( pool_size = (2,2)),
    Flatten(),
    Dense( 64, "relu"),
    Dropout(0.5),
    Dense( 64, "relu"),
    Dropout( 0.5),
    Dense( 10, "softmax")
])

(xtr,ytr),(xts,yts) = mnist.load_data()

xtr = xtr.reshape( -1, 28, 28, 1).astype( "float32")/255.0
xts = xts.reshape( -1, 28, 28, 1).astype( "float32")/255.0

le = LabelBinarizer()
ytr = le.fit_transform( ytr)
yts = le.transform( yts)

model.compile( loss = "categorical_crossentropy", optimizer = Adam( learning_rate = 0.001), metrics = [ "accuracy"])

H = model.fit( xtr, ytr, validation_data = (xts,yts), batch_size = 128, epochs = 10, verbose = 1)

print( classification_report( yts.argmax( axis=1), model.predict( xts).argmax( axis=1), target_names = [ str(x) for x in le.classes_]))

model.save( "digit_classifier.h5")